{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# List of Imports\n",
    "from __future__ import print_function\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_curve,roc_auc_score,auc\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import sympy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = 'ActivityEncoded'\n",
    "LABELS = ['Fall','Non Fall']\n",
    "TIME_PERIODS = 80\n",
    "STEP_DISTANCE = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df(value):\n",
    "    \n",
    "    if value == 0:\n",
    "        df_stats_G = pd.read_csv(r'C:\\Users\\Ash\\Desktop\\MobiFall Datasets cleaned\\Stats\\df with stats G.csv')\n",
    "        df_test_G  = df_stats_G[df_stats_G['User'] > 38]\n",
    "        df_train_G = df_stats_G[df_stats_G['User'] <= 38]\n",
    "    \n",
    "    if value == 1:\n",
    "        df_test_G = pd.read_csv(r'C:\\Users\\Ash\\Desktop\\MobiFall Datasets cleaned\\SMOTE\\df test SMOTE G with stats.csv')\n",
    "        df_train_G = pd.read_csv(r'C:\\Users\\Ash\\Desktop\\MobiFall Datasets cleaned\\SMOTE\\df train SMOTE G with stats.csv')\n",
    "    \n",
    "    return df_test_G,df_train_G\n",
    "\n",
    "STATS = 0\n",
    "SMOTE_STATS = 1\n",
    "\n",
    "df_test,df_train = df(STATS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This functions creates segments of the training set, essentially creating a better form that will be accepted by KERAS but can also be used by supervised learning \n",
    "def create_segments_and_labels(df, time_steps, step, label_name):\n",
    "\n",
    "    N_FEATURES = 3\n",
    "    segments = []\n",
    "    labels = []\n",
    "    for i in range(0, len(df) - time_steps, step):\n",
    "        xs = df['Gx'].values[i: i + time_steps]\n",
    "        ys = df['Gy'].values[i: i + time_steps]\n",
    "        zs = df['Gz'].values[i: i + time_steps]\n",
    "     \n",
    "        label = stats.mode(df[label_name][i: i + time_steps])[0][0]\n",
    "        segments.append([xs, ys, zs])\n",
    "        labels.append(label)\n",
    "\n",
    "\n",
    "    reshaped_segments = np.asarray(segments, dtype= np.float32).reshape(-1, time_steps, N_FEATURES)\n",
    "    labels = np.asarray(labels)\n",
    "\n",
    "    return reshaped_segments, labels\n",
    "\n",
    "def create_segments_and_labels_stats(df, time_steps, step, label_name):\n",
    "\n",
    "    N_FEATURES = 3\n",
    "    segments = []\n",
    "    labels = []\n",
    "    for i in range(0, len(df) - time_steps, step):\n",
    "        xs = df['Gx'].values[i: i + time_steps]\n",
    "        ys = df['Gy'].values[i: i + time_steps]\n",
    "        zs = df['Gz'].values[i: i + time_steps]\n",
    "     \n",
    "        label = stats.mode(df[label_name][i: i + time_steps])[0][0]\n",
    "        segments.append([xs, ys, zs])\n",
    "        labels.append(label)\n",
    "\n",
    "\n",
    "    reshaped_segments = np.asarray(segments, dtype= np.float32).reshape(-1, time_steps, N_FEATURES)\n",
    "    labels = np.asarray(labels)\n",
    "\n",
    "    return reshaped_segments, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
